---
title: "Assignment 2"
author: "Puneet"
date: "January 22, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
rm(list=ls())  
text.clean = function(text,user_stop_words)                    # text data
{ require("tidytext")
  require('tibble')
  require('stringr')
  require('dplyr')
  text = gsub("<.*?>", " ", text) 	# regex for removing HTML tags
  
  textdf = data_frame(text = text)    
  stpw1 = user_stop_words
  stpw2 = data_frame(word=stpw1,lexicon ='SMART')
  stpw3 = stop_words
  stpw4 = rbind(stpw2,stpw3)
     
  x <-textdf %>% unnest_tokens(word, text) %>%anti_join(stpw4)
  return(x)  
}



create.dtm = function(data)
{
  require('tm')
  require(text2vec)
  input = data
  x <- Corpus(VectorSource(input))
  dtm_tf <- DocumentTermMatrix(x)
  return(dtm_tf) 
}


#--------------------------------------------------------#
## Step 3:     # Build word cloud_bar_cog                #
#--------------------------------------------------------#
build_wordcloud_bar_cog <- function(dtm, 
                                max.words1, # max no. of words to accommodate
                                min.freq,   # min.freq of words to consider
                                title1,central_nodes,connections){        # write within double quotes
require(wordcloud)
if (ncol(dtm) > 20000){   # if dtm is overly large, break into chunks and solve

tst = round(ncol(dtm)/100)  # divide DTM's cols into 100 manageble parts
a = rep(tst,99)
b = cumsum(a);rm(a)
b = c(0,b,ncol(dtm))

ss.col = c(NULL)
for (i in 1:(length(b)-1)) {
  tempdtm = dtm[,(b[i]+1):(b[i+1])]
  s = colSums(as.matrix(tempdtm))
  ss.col = c(ss.col,s)
  print(i)      } # i loop ends

tsum = ss.col

 } else { tsum = apply(dtm, 2, sum) }

tsum = tsum[order(tsum, decreasing = T)]       #terms in decreasing order of freq
# head(tsum)
# tail(tsum)

# windows()  # New plot window
 wordcloud(names(tsum), tsum,     # words, their freqs 
          scale = c(3.5, 0.5),     # range of word sizes
          min.freq,                     # min.freq of words to consider
          max.words = max.words1,       # max #words
          colors = brewer.pal(8, "Dark2"))    # Plot results in a word cloud 
 title(sub = title1)     # title for the wordcloud display


a0 = apply(dtm, 2, sum)
a1 = order(a0, decreasing = TRUE)
tsum = a0[a1]

# plot barchart for top tokens
test = as.data.frame(round(tsum[1:15],0))

# windows()  # New plot window
require(ggplot2)
ggplot(test, aes(x = rownames(test), y = test)) + 
       geom_bar(stat = "identity", fill = "Blue") +
       geom_text(aes(label = test), vjust= -0.20) + 
       theme(axis.text.x = element_text(angle = 90, hjust = 1))


dtm1 = as.matrix(dtm)   # need it as a regular matrix for matrix ops like %*% to apply
adj.mat = t(dtm1) %*% dtm1    # making a square symmatric term-term matrix 
diag(adj.mat) = 0     # no self-references. So diag is 0.
a0 = order(apply(adj.mat, 2, sum), decreasing = T)   # order cols by descending colSum
mat1 = as.matrix(adj.mat[a0[1:50], a0[1:50]])   # taking the top 50 rows and cols only
  library(igraph)
  a = colSums(mat1) # collect colsums into a vector obj a
  b = order(-a)     # nice syntax for ordering vector in decr order  
  
  mat2 = mat1[b, b]     # order both rows and columns along vector b
  
  diag(mat2) =  0
  
  ## +++ go row by row and find top k adjacencies +++ ##

  wc = NULL
  s = central_nodes
  k1 = connections

 for (i1 in 1:s){ 
    thresh1 = mat2[i1,][order(-mat2[i1, ])[k1]]
    mat2[i1, mat2[i1,] < thresh1] = 0   # neat. didn't need 2 use () in the subset here.
    mat2[i1, mat2[i1,] > 0 ] = 1
    word = names(mat2[i1, mat2[i1,] > 0])
    mat2[(i1+1):nrow(mat2), match(word,colnames(mat2))] = 0
    wc = c(wc,word)
  } # i1 loop ends
  
  
  mat3 = mat2[match(wc, colnames(mat2)), match(wc, colnames(mat2))]
  ord = colnames(mat2)[which(!is.na(match(colnames(mat2), colnames(mat3))))]  # removed any NAs from the list
  mat4 = mat3[match(ord, colnames(mat3)), match(ord, colnames(mat3))]
  graph <- graph.adjacency(mat4, mode = "undirected", weighted=T)    # Create Network object
  graph = simplify(graph) 
  V(graph)$color[1:s] = "green"
  V(graph)$color[(s+1):length(V(graph))] = "pink"

  graph = delete.vertices(graph, V(graph)[ degree(graph) == 0 ]) # delete singletons?
  
  plot(graph, 
       layout = layout.kamada.kawai, 
       main = title1)

    } # func ends

#--------------------------------------------------------#
##  # Build word cloud, Bar Chart and COG function ends  #
#--------------------------------------------------------#




temp.text = readLines('https://raw.githubusercontent.com/sudhir-voleti/sample-data-sets/master/International%20Business%20Machines%20(IBM)%20Q3%202016%20Results%20-%20Earnings%20Call%20Transcript.txt') 
my_stop_words = c('ibm','q3','results')
clean.text = text.clean(temp.text,my_stop_words) 
dtm=create.dtm(clean.text)
dtm
build_wordcloud_bar_cog(dtm, 100, 2, "IBM analyst call",5,5) 
```

## R Markdown